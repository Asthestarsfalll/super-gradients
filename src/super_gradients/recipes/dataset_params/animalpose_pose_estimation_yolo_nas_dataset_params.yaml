num_joints: 20

# Important note - original dataset did not provide sigma scores, so we use values 0.1 for all keypoints.
oks_sigmas: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]

flip_indexes: [1,0,2,4,3,6,5,8,7,10,9,12,11,14,13,16,15,17,18,19]

edge_links:
  - [0, 1]
  - [0, 2]
  - [1, 2]
  - [0, 3]
  - [1, 4]
  - [2, 17]
  - [18, 19]
  - [5, 9]
  - [6, 10]
  - [7, 11]
  - [8, 12]
  - [9, 13]
  - [10, 14]
  - [11, 15 ]
  - [12, 16 ]

edge_colors:
  - [127, 0, 255]
  - [91, 56, 253]
  - [55, 109, 248]
  - [19, 157, 241]
  - [18, 199, 229]
  - [54, 229, 215]
  - [90, 248, 199]
  - [128, 254, 179]
  - [164, 248, 158]
  - [200, 229, 135]
  - [236, 199, 110]
  - [255, 157, 83]
  - [255, 109, 56]
  - [255, 56, 28]
  - [255, 0, 0]


keypoint_colors:
  - [148, 0, 211]
  - [75, 0, 130]
  - [0, 0, 255]
  - [0, 255, 0]
  - [255, 255, 0]
  - [255, 165, 0]
  - [255, 69, 0]
  - [255, 0, 0]
  - [139, 0, 0]
  - [128, 0, 128]
  - [238, 130, 238]
  - [186, 85, 211]
  - [148, 0, 211]
  - [0, 255, 255]
  - [0, 128, 128]
  - [0, 0, 139]
  - [0, 0, 255]
  - [0, 255, 0]
  - [255, 69, 0]
  - [255, 165, 0]

# This is a shortcut parameter to set size of training & validation images.
image_size: 640
dataset_params_suffix: "${dataset_params.image_size}"

train_dataset_params:
  data_dir: /data/animalpose # root path to coco data
  images_dir: images
  json_file: train_keypoints.json

  edge_links: ${dataset_params.edge_links}
  edge_colors: ${dataset_params.edge_colors}
  keypoint_colors: ${dataset_params.keypoint_colors}

  transforms:
    - KeypointsRandomHorizontalFlip:
        # Note these indexes are COCO-specific. If you're using a different dataset, you'll need to change these accordingly.
        flip_index: ${dataset_params.flip_indexes}
        prob: 0.5

    - KeypointsHSV:
        prob: 0.5
        hgain: 20
        sgain: 20
        vgain: 20

    - KeypointsBrightnessContrast:
        prob: 0.5
        brightness_range: [ 0.8, 1.2 ]
        contrast_range: [ 0.8, 1.2 ]

    - KeypointsMosaic:
        prob: 0.8

    - KeypointsRandomAffineTransform:
        max_rotation: 0
        min_scale: 0.5
        max_scale: 1.5
        max_translate: 0.1
        image_pad_value: 127
        mask_pad_value: 1
        prob: 0.75
        interpolation_mode: [ 0, 1, 2, 3, 4 ]

    - KeypointsLongestMaxSize:
        max_height: ${dataset_params.image_size}
        max_width: ${dataset_params.image_size}

    - KeypointsPadIfNeeded:
        min_height: ${dataset_params.image_size}
        min_width: ${dataset_params.image_size}
        image_pad_value: [ 127, 127, 127 ]
        mask_pad_value: 1
        padding_mode: center

    - KeypointsImageStandardize:
        max_value: 255

    - KeypointsImageNormalize:
        mean: [ 0.485, 0.456, 0.406 ]
        std: [ 0.229, 0.224, 0.225 ]

    - KeypointsRemoveSmallObjects:
        min_instance_area: 1
        min_visible_keypoints: 1

val_dataset_params:
  data_dir: /data/animalpose
  images_dir: images
  json_file: val_keypoints.json

  edge_links: ${dataset_params.edge_links}
  edge_colors: ${dataset_params.edge_colors}
  keypoint_colors: ${dataset_params.keypoint_colors}

  transforms:
    - KeypointsLongestMaxSize:
        max_height: ${dataset_params.image_size}
        max_width: ${dataset_params.image_size}

    - KeypointsPadIfNeeded:
        min_height: ${dataset_params.image_size}
        min_width: ${dataset_params.image_size}
        image_pad_value: 127
        mask_pad_value: 1
        padding_mode: bottom_right

    - KeypointsImageStandardize:
        max_value: 255

    - KeypointsImageNormalize:
        mean: [ 0.485, 0.456, 0.406 ]
        std: [ 0.229, 0.224, 0.225 ]


train_dataloader_params:
  dataset: AnimalPoseEstimationDataset
  shuffle: True
  batch_size: 32
  num_workers: 8
  drop_last: True
  pin_memory: False
  collate_fn: YoloNASPoseCollateFN

val_dataloader_params:
  dataset: AnimalPoseEstimationDataset
  batch_size: 32
  num_workers: 8
  drop_last: False
  pin_memory: False
  collate_fn: YoloNASPoseCollateFN
