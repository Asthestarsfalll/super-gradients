# YOLO-NAS-POSE training on COCO2017 Human Pose Estimation Dataset:
# YOLO-NAS-POSE-L trained in 640x640
# Recipe runs with batch size = 48 X 8 gpus = 384.

# Instructions:
#   0. Make sure that the data is stored in dataset_params.train_dataset_params.data_dir or
#      set "dataset_params.train_dataset_params.data_dir" at the end of the command below:
#      python -m super_gradients.train_from_recipe --config-name=... \
#                 dataset_params.train_dataset_params.data_dir=<PATH_TO_DATASET> \
#                 dataset_params.val_dataset_params.data_dir=<PATH_TO_DATASET>
#   1. Move to the project root (where you will find the ReadMe and src folder)
#   2. Run the command you want:
#         yolo_nas_pose_s: python -m super_gradients.train_from_recipe --config-name=coco2017_pose_yolo_pose_s
#         yolo_nas_pose_m: python -m super_gradients.train_from_recipe --config-name=coco2017_pose_yolo_pose_m
#         yolo_nas_pose_l: python -m super_gradients.train_from_recipe --config-name=coco2017_pose_yolo_pose_l
#
# Training times and accuracies (mAP@0.5-0.95):
#         yolo_nas_pose_s: 38h on 8 NVIDIA GeForce RTX 3090, mAP: 58.1 (val)
#         yolo_nas_pose_m: 72h on 8 NVIDIA GeForce RTX 3090, mAP: 60.52 (val)
#         yolo_nas_pose_l: 141h on 8 NVIDIA GeForce RTX 3090, mAP: 63.33 (val)
#

defaults:
  - coco2017_pose_yolo_pose_l

architecture: yolo_nas_pose_s

checkpoint_params:
  # We start training by loading the weights of the pretrained model for detection task
  pretrained_weights: "https://sghub.deci.ai/models/yolo_nas_s_coco.pth"
  strict_load: key_matching

dataset_params:
  train_dataloader_params:
    batch_size: 48

  val_dataloader_params:
    batch_size: 48
