{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Offline evaluation of Pose Estimation models using PyCocoTools\n",
    "\n",
    "This example shows how you can evaluate pose estimation models using PyCocoEval class from pycocotools python package.\n",
    "Although we provide a ready-to-use metric class to compute average precision (AP) and average recall (AR) scores, the \n",
    "evaluation protocol during validation is slightly different from what pycocotools suggests for academic evaluation.\n",
    "\n",
    "In particular:\n",
    "\n",
    "## SG\n",
    "\n",
    "* In SG, during training/validation, we resize all images to a fixed size (Default is 640x640) using aspect-ratio preserving resize of the longest size + padding. \n",
    "* Our metric evaluate AP/AR in the resolution of the resized & padded images, **not in the resolution of original image**. \n",
    "\n",
    "\n",
    "## COCOEval\n",
    "\n",
    "* In COCOEval all images are not resized and pose predictions are evaluated in the resolution of original image \n",
    "\n",
    "Because of this discrepancy, metrics reported by `PoseEstimationMetrics` class is usually a bit lower (Usually by ~1AP) than the ones \n",
    "you would get from the same model if computed with COCOEval. \n",
    "\n",
    "For this reason we provide this example to show how you can compute metrics using COCOEval for pose estimation models that are available in SuperGradients."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f36fcd2e6daa861c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instantiate the model for evaluation\n",
    "\n",
    "First, let's instantiate the model we are going to evaluate. \n",
    "You can use either pretrained models or provide a checkpoint path to your own trained checkpoint.\n",
    "\n",
    "```python\n",
    "# This is how you can load your custom checkpoint instead of pretrained one\n",
    "model = models.get(\n",
    "    Models.YOLO_NAS_POSE_L,\n",
    "    num_classes=17,\n",
    "    checkpoint_path=\"G:/super-gradients/checkpoints/coco2017_yolo_nas_pose_l_ckpt_best.pth\",\n",
    ")\n",
    "```\n",
    "In this example we will be using pretrained weights for simplicity."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33367b7bd09fccbb"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The console stream is logged into C:\\Users\\ekhve\\sg_logs\\console.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-28 09:19:49] INFO - crash_tips_setup.py - Crash tips is enabled. You can set your environment variable to CRASH_HANDLER=FALSE to disable it\n",
      "[2023-09-28 09:19:51] WARNING - redirects.py - NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0928 09:19:51.855809 18076 redirects.py:27] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "C:\\Users\\ekhve\\.conda\\envs\\sg\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "[2023-09-28 09:19:56] WARNING - env_sanity_check.py - \u001B[31mFailed to verify operating system: Deci officially supports only Linux kernels. Some features may not work as expected.\u001B[0m\n",
      "W0928 09:19:56.457413 18076 env_sanity_check.py:30] \u001B[31mFailed to verify operating system: Deci officially supports only Linux kernels. Some features may not work as expected.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from super_gradients.common.object_names import Models\n",
    "from super_gradients.training import models\n",
    "\n",
    "model = models.get(\n",
    "    Models.YOLO_NAS_POSE_L,\n",
    "    num_classes=17,\n",
    "    checkpoint_path=\"G:/super-gradients/checkpoints/coco2017_yolo_nas_pose_l_ckpt_best.pth\",\n",
    "    # pretrained_weights=\"coco_pose\" TODO: Replace when weights are on S3\n",
    ").cuda()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T06:19:59.432867200Z",
     "start_time": "2023-09-28T06:19:47.290180800Z"
    }
   },
   "id": "36c9acfa4c5057c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare COCO validation data\n",
    "\n",
    "Next, we obtain list of images in COCO2017 validation set and load their annotations.\n",
    "You may want to either set the COCO_ROOT_DIR environment variable where COCO2017 data is located on your machine or edit the default path directylu"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "372d6ce9605c68f9"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "['annotations', 'images']"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "COCO_DATA_DIR = os.environ.get(\"COCO_ROOT_DIR\", \"g:/coco2017\")\n",
    "os.listdir(COCO_DATA_DIR)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T07:02:01.395323Z",
     "start_time": "2023-09-28T07:02:01.366786200Z"
    }
   },
   "id": "91e2ee3f26130e1a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once data is set we can load it"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a8be6a43b014149"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from pycocotools.cocoeval import COCOeval"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-28T06:19:46.796270800Z"
    }
   },
   "id": "ca413a0cfd65d3d9"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "\n",
    "images_path = os.path.join(COCO_DATA_DIR, \"images/val2017\")\n",
    "image_files = [os.path.join(images_path, x) for x in os.listdir(images_path)]\n",
    "\n",
    "gt_annotations_path = os.path.join(COCO_DATA_DIR, \"annotations/person_keypoints_val2017.json\")\n",
    "gt = COCO(gt_annotations_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T06:21:27.099644500Z",
     "start_time": "2023-09-28T06:21:26.297582500Z"
    }
   },
   "id": "31ef5c6c808fc5c2"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Images: 100%|██████████| 5000/5000 [01:41<00:00, 49.44it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(\n",
    "    image_files, conf=0.01, iou=0.7, pre_nms_max_predictions=300, post_nms_max_predictions=20, fuse_model=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T06:44:59.586933800Z",
     "start_time": "2023-09-28T06:42:59.194074900Z"
    }
   },
   "id": "7d20871ce397f6cb"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.85s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.675\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.880\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.748\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = 0.633\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.744\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.731\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.918\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.796\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = 0.686\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.795\n",
      "Loading and preparing results...\n",
      "DONE (t=2.81s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *keypoints*\n",
      "DONE (t=17.44s).\n",
      "Accumulating evaluation results...\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import json_tricks as json\n",
    "import collections\n",
    "import numpy as np\n",
    "import tempfile\n",
    "\n",
    "def predictions_to_coco(predictions, image_files):\n",
    "    predicted_poses = []\n",
    "    predicted_scores = []\n",
    "    non_empty_image_ids = []\n",
    "    for image_file, image_predictions in zip(image_files, predictions):\n",
    "        non_empty_image_ids.append(int(os.path.splitext(os.path.basename(image_file))[0]))\n",
    "        predicted_poses.append(image_predictions.prediction.poses)\n",
    "        predicted_scores.append(image_predictions.prediction.scores)\n",
    "\n",
    "    coco_pred = _coco_convert_predictions_to_dict(predicted_poses, predicted_scores, non_empty_image_ids)\n",
    "    return coco_pred\n",
    "\n",
    "def _coco_process_keypoints(keypoints):\n",
    "    tmp = keypoints.copy()\n",
    "    if keypoints[:, 2].max() > 0:\n",
    "        num_keypoints = keypoints.shape[0]\n",
    "        for i in range(num_keypoints):\n",
    "            tmp[i][0:3] = [float(keypoints[i][0]), float(keypoints[i][1]), float(keypoints[i][2])]\n",
    "\n",
    "    return tmp\n",
    "\n",
    "def _coco_convert_predictions_to_dict(predicted_poses, predicted_scores, image_ids):\n",
    "    kpts = collections.defaultdict(list)\n",
    "    for poses, scores, image_id_int in zip(predicted_poses, predicted_scores, image_ids):\n",
    "\n",
    "        for person_index, kpt in enumerate(poses):\n",
    "            area = (np.max(kpt[:, 0]) - np.min(kpt[:, 0])) * (np.max(kpt[:, 1]) - np.min(kpt[:, 1]))\n",
    "            kpt = _coco_process_keypoints(kpt)\n",
    "            kpts[image_id_int].append({\"keypoints\": kpt[:, 0:3], \"score\": float(scores[person_index]), \"image\": image_id_int, \"area\": area})\n",
    "\n",
    "    oks_nmsed_kpts = []\n",
    "    # image x person x (keypoints)\n",
    "    for img in kpts.keys():\n",
    "        # person x (keypoints)\n",
    "        img_kpts = kpts[img]\n",
    "        # person x (keypoints)\n",
    "        # do not use nms, keep all detections\n",
    "        keep = []\n",
    "        if len(keep) == 0:\n",
    "            oks_nmsed_kpts.append(img_kpts)\n",
    "        else:\n",
    "            oks_nmsed_kpts.append([img_kpts[_keep] for _keep in keep])\n",
    "\n",
    "    classes = [\"__background__\", \"person\"]\n",
    "    _class_to_coco_ind = {cls: i for i, cls in enumerate(classes)}\n",
    "\n",
    "    data_pack = [\n",
    "        {\"cat_id\": _class_to_coco_ind[cls], \"cls_ind\": cls_ind, \"cls\": cls, \"ann_type\": \"keypoints\", \"keypoints\": oks_nmsed_kpts}\n",
    "        for cls_ind, cls in enumerate(classes)\n",
    "        if not cls == \"__background__\"\n",
    "    ]\n",
    "\n",
    "    results = _coco_keypoint_results_one_category_kernel(data_pack[0], num_joints=17)\n",
    "    return results\n",
    "\n",
    "def _coco_keypoint_results_one_category_kernel(data_pack, num_joints: int):\n",
    "    cat_id = data_pack[\"cat_id\"]\n",
    "    keypoints = data_pack[\"keypoints\"]\n",
    "    cat_results = []\n",
    "\n",
    "    for img_kpts in keypoints:\n",
    "        if len(img_kpts) == 0:\n",
    "            continue\n",
    "\n",
    "        _key_points = np.array([img_kpts[k][\"keypoints\"] for k in range(len(img_kpts))])\n",
    "        key_points = np.zeros((_key_points.shape[0], num_joints * 3), dtype=np.float32)\n",
    "\n",
    "        for ipt in range(num_joints):\n",
    "            key_points[:, ipt * 3 + 0] = _key_points[:, ipt, 0]\n",
    "            key_points[:, ipt * 3 + 1] = _key_points[:, ipt, 1]\n",
    "            # keypoints score.\n",
    "            key_points[:, ipt * 3 + 2] = _key_points[:, ipt, 2]\n",
    "\n",
    "        for k in range(len(img_kpts)):\n",
    "            kpt = key_points[k].reshape((num_joints, 3))\n",
    "            left_top = np.amin(kpt, axis=0)\n",
    "            right_bottom = np.amax(kpt, axis=0)\n",
    "\n",
    "            w = right_bottom[0] - left_top[0]\n",
    "            h = right_bottom[1] - left_top[1]\n",
    "\n",
    "            cat_results.append(\n",
    "                {\n",
    "                    \"image_id\": img_kpts[k][\"image\"],\n",
    "                    \"category_id\": cat_id,\n",
    "                    \"keypoints\": list(key_points[k]),\n",
    "                    \"score\": img_kpts[k][\"score\"],\n",
    "                    \"bbox\": list([left_top[0], left_top[1], w, h]),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return cat_results\n",
    "\n",
    "coco_pred = predictions_to_coco(predictions, image_files)\n",
    "\n",
    "with tempfile.TemporaryDirectory() as td:\n",
    "    res_file = os.path.join(td, \"keypoints_coco2017_results.json\")\n",
    "\n",
    "    with open(res_file, \"w\") as f:\n",
    "        json.dump(coco_pred, f)\n",
    "\n",
    "    coco_dt = copy.deepcopy(gt)\n",
    "    coco_dt = coco_dt.loadRes(res_file)\n",
    "\n",
    "    coco_evaluator = COCOeval(gt, coco_dt, iouType=\"keypoints\")\n",
    "    coco_evaluator.evaluate()  # run per image evaluation\n",
    "    coco_evaluator.accumulate()  # accumulate per image results\n",
    "    coco_evaluator.summarize()  # display summary metrics of results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T06:51:05.105331500Z",
     "start_time": "2023-09-28T06:48:02.712514700Z"
    }
   },
   "id": "a077a3e5d1ed0342"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.67541086, 0.88030538, 0.74760717, 0.63302696, 0.74432253,\n       0.73090365, 0.91829345, 0.7961272 , 0.68634253, 0.79483463])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_evaluator.stats"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T06:51:05.134357400Z",
     "start_time": "2023-09-28T06:51:05.098325Z"
    }
   },
   "id": "bc3ab706ff4eeb9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7f1f02de114a3ed4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
