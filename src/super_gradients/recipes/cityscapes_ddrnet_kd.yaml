defaults:
  - training_hyperparams: cityscapes_default_train_params
  - dataset_params: cityscapes_ddrnet_dataset_params
  - checkpoint_params: default_checkpoint_params
  - _self_

train_dataloader: cityscapes_train
val_dataloader: cityscapes_val

resume: False
training_hyperparams:
  sync_bn: True
  max_epochs: 500
  initial_lr: 0.0075   # batch size 24
  resume: ${resume}
  loss:
    _target_: super_gradients.training.losses.seg_kd_loss.SegKDLoss
    weights: [ 1. , 0.]
    kd_loss_weights: [1., 6.]

    kd_loss:
      _target_: super_gradients.training.losses.cwd_loss.CWDKlDivLoss
      temperature: 3.
      normalization_mode: channel_wise

    ce_loss:
      _target_: torch.nn.CrossEntropyLoss
      ignore_index: 19

  sg_logger: wandb_sg_logger
  sg_logger_params:
    project_name: KD-Segmentation
    entity: algo
    api_server: https://wandb.research.deci.ai
    save_checkpoints_remote: True
    save_tensorboard_remote: True
    save_logs_remote: True

student_arch_params:
  num_classes: 19
  aux_head: True

teacher_arch_params:
  num_classes: 19
  aux_head: True

arch_params:

teacher_checkpoint_params:
  load_backbone: False
  checkpoint_path: # checkpoint path that is not located in super_gradients/checkpoints
  strict_load: no_key_matching
  pretrained_weights: cityscapes_auto_label

student_checkpoint_params:
  load_backbone: True
  checkpoint_path: # checkpoint path that is not located in super_gradients/checkpoints
  strict_load: no_key_matching
  pretrained_weights: # a string describing the dataset of the pretrained weights (for example "imagenent").


run_teacher_on_eval: True

experiment_name: ddrnet_23_slim_KD

ckpt_root_dir:

multi_gpu: DDP
num_gpus: 4

architecture: kd_module
student_architecture: ddrnet_23_slim
teacher_architecture: ddrnet_39


# THE FOLLOWING PARAMS ARE DIRECTLY USED BY HYDRA
hydra:
  run:
    # Set the output directory (i.e. where .hydra folder that logs all the input params will be generated)
    dir: ${hydra_output_dir:${ckpt_root_dir}, ${experiment_name}}
